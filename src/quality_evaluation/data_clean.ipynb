{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cleaning.py\n",
    "# Contains functions to detect and handle inconsistent data and outliers\n",
    "# Input:\n",
    "#     - data/educatec_data/merged_educatec_moodle.csv\n",
    "# Output:\n",
    "#     - data/working_data/cleaned_data.csv\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the csv file from file_path\n",
    "    :param file_path: Path - path to the csv file\n",
    "    :return: pd.DataFrame - loaded dataframe\n",
    "    \"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis Exploratorio de Datos (EDA)\n",
    "Antes de realizar cualquier limpieza, es importante entender el estado actual de los datos. Realizamos un análisis exploratorio de datos para obtener información sobre el número de filas, columnas, tipos de datos y valores faltantes.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(df, file_name):\n",
    "    \"\"\"\n",
    "    Perform exploratory data analysis on the dataframe\n",
    "    :param df: pd.DataFrame - dataframe to analyze\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    num_zeros = (df == '0').sum().sum() + (df == 0).sum().sum()\n",
    "    num_na = df.isnull().sum().sum() + num_zeros\n",
    "\n",
    "    print(f\"Número de valores nulos (incluyendo '0' y 0): {num_na}\")\n",
    "    print(f\"Número de 'Sin respuesta': {(df == 'Sin respuesta').sum().sum()}\")\n",
    "    print(f\"Número de 'Sin fecha': {(df == 'Sin fecha').sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aseguramos la calidad de los datos limpiando los valores que tengan 'Sin respuesta', 'Sin fecha', o que sean valores nulos para después eliminar esos datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_missing_values(df):\n",
    "    \"\"\"\n",
    "    Replace 'sin respuesta' and 'sin fecha' with NaN\n",
    "    :param df: pd.DataFrame - dataframe to process\n",
    "    :return: pd.DataFrame - dataframe with missing values replaced\n",
    "    \"\"\"\n",
    "    return df.replace(['Sin respuesta', 'Sin fecha', '0', 0, ''], pd.NA)\n",
    "\n",
    "def drop_invalid_rows(df, file_name):\n",
    "    \"\"\"\n",
    "    Drop rows with any NaN values.\n",
    "    :param df: pd.DataFrame - dataframe to process\n",
    "    :param file_name: str - name of the file being processed\n",
    "    :return: pd.DataFrame - dataframe with invalid rows dropped\n",
    "    \"\"\"\n",
    "    print(f\"Shape of {file_name} before dropping invalid rows: {df.shape}\")\n",
    "    df = df.dropna()\n",
    "    print(f\"Shape of {file_name} after dropping invalid rows: {df.shape}\")\n",
    "    return df\n",
    "\n",
    "def detect_inconsistencies(df):\n",
    "    \"\"\"\n",
    "    Detect and report inconsistencies in the dataset\n",
    "    :param df: pd.DataFrame - dataframe to analyze\n",
    "    :return: pd.DataFrame - dataframe with inconsistencies marked\n",
    "    \"\"\"\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        df[f'{col}_inconsistent'] = df[col] < 0\n",
    "    return df\n",
    "\n",
    "def impute_missing_values(df):\n",
    "    \"\"\"\n",
    "    Impute missing values in the dataframe\n",
    "    :param df: pd.DataFrame - dataframe to process\n",
    "    :return: pd.DataFrame - dataframe with missing values imputed\n",
    "    \"\"\"\n",
    "    # Set the option to opt-in to the future behavior for fillna\n",
    "    pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "    # Impute numerical columns with mean\n",
    "    num_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[num_cols] = df[num_cols].fillna(df[num_cols].mean())\n",
    "\n",
    "    # Impute categorical columns with mode\n",
    "    cat_cols = df.select_dtypes(exclude=[np.number]).columns\n",
    "    for col in cat_cols:\n",
    "        mode = df[col].mode()[0] if not df[col].mode().empty else pd.NA\n",
    "        df[col] = df[col].fillna(mode)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def detect_outliers(df):\n",
    "    \"\"\"\n",
    "    Detect and report outliers in the dataset\n",
    "    :param df: pd.DataFrame - dataframe to analyze\n",
    "    :return: pd.DataFrame - dataframe with outliers marked\n",
    "    \"\"\"\n",
    "    for col in df.select_dtypes(include=[np.number]).columns:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df[f'{col}_outlier'] = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "    return df\n",
    "\n",
    "def cleaning(input_data_path, output_data_path):\n",
    "    \"\"\"\n",
    "    Perform data cleaning on the dataset\n",
    "    :param input_data_path: Path - path to the input dataset\n",
    "    :param output_data_path: Path - path to save the cleaned dataset\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    file_name = os.path.basename(input_data_path)\n",
    "    dataset = load_data(input_data_path)\n",
    "    print(f\"Resumen del archivo antes de la limpieza: {file_name}\")\n",
    "    eda(dataset, file_name)  # EDA antes de la limpieza\\n\",\n",
    "    dataset = replace_missing_values(dataset)\n",
    "    dataset = drop_invalid_rows(dataset, file_name)\n",
    "    dataset = detect_inconsistencies(dataset)\n",
    "    dataset = impute_missing_values(dataset)\n",
    "    dataset = detect_outliers(dataset)\n",
    "    print(f\"Resumen del archivo después de la limpieza: {file_name}\")\n",
    "    eda(dataset, file_name)  # EDA después de la limpieza\\n\",\n",
    "    dataset.to_csv(output_data_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Educatec Directory: /Users/administrador/Downloads/Leaders4Edu/data/educatec_data\n",
      "Moodle Directory: /Users/administrador/Downloads/Leaders4Edu/data/moodle_data\n",
      "Working Directory: /Users/administrador/Downloads/Leaders4Edu/data/working_data\n"
     ]
    }
   ],
   "source": [
    "# Configurar rutas relativas para los directorios de datos\n",
    "educatec_directory = os.path.join(os.getcwd(), \"..\", \"..\", \"data\", \"educatec_data\")\n",
    "moodle_directory = os.path.join(os.getcwd(), \"..\", \"..\", \"data\", \"moodle_data\")\n",
    "working_directory = os.path.join(os.getcwd(), \"..\", \"..\", \"data\", \"working_data\")\n",
    "\n",
    "# Convertir a objetos Path y resolver las rutas\n",
    "educatec_directory_path = Path(educatec_directory).resolve()\n",
    "moodle_directory_path = Path(moodle_directory).resolve()\n",
    "working_directory_path = Path(working_directory).resolve()\n",
    "\n",
    "# Imprimir las rutas para verificar\n",
    "print(\"Educatec Directory:\", educatec_directory_path)\n",
    "print(\"Moodle Directory:\", moodle_directory_path)\n",
    "print(\"Working Directory:\", working_directory_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen del archivo antes de la limpieza: educatec.csv\n",
      "Número de valores nulos (incluyendo '0' y 0): 0\n",
      "Número de 'Sin respuesta': 202212\n",
      "Número de 'Sin fecha': 202212\n",
      "Shape of educatec.csv before dropping invalid rows: (205260, 7)\n",
      "Shape of educatec.csv after dropping invalid rows: (3048, 7)\n",
      "Resumen del archivo después de la limpieza: educatec.csv\n",
      "Número de valores nulos (incluyendo '0' y 0): 6096\n",
      "Número de 'Sin respuesta': 0\n",
      "Número de 'Sin fecha': 0\n",
      "Resumen del archivo antes de la limpieza: course_modules_completion.csv\n",
      "Número de valores nulos (incluyendo '0' y 0): 833037\n",
      "Número de 'Sin respuesta': 0\n",
      "Número de 'Sin fecha': 0\n",
      "Shape of course_modules_completion.csv before dropping invalid rows: (4710592, 6)\n",
      "Shape of course_modules_completion.csv after dropping invalid rows: (3878191, 6)\n",
      "Resumen del archivo después de la limpieza: course_modules_completion.csv\n",
      "Número de valores nulos (incluyendo '0' y 0): 23263990\n",
      "Número de 'Sin respuesta': 0\n",
      "Número de 'Sin fecha': 0\n",
      "Resumen del archivo antes de la limpieza: course_modules.csv\n",
      "Número de valores nulos (incluyendo '0' y 0): 7030\n",
      "Número de 'Sin respuesta': 0\n",
      "Número de 'Sin fecha': 0\n",
      "Shape of course_modules.csv before dropping invalid rows: (29084, 7)\n",
      "Shape of course_modules.csv after dropping invalid rows: (22571, 7)\n",
      "Resumen del archivo después de la limpieza: course_modules.csv\n",
      "Número de valores nulos (incluyendo '0' y 0): 180568\n",
      "Número de 'Sin respuesta': 0\n",
      "Número de 'Sin fecha': 0\n",
      "Resumen del archivo antes de la limpieza: user_info_data.csv\n",
      "Número de valores nulos (incluyendo '0' y 0): 13884\n",
      "Número de 'Sin respuesta': 0\n",
      "Número de 'Sin fecha': 0\n",
      "Shape of user_info_data.csv before dropping invalid rows: (2886236, 4)\n",
      "Shape of user_info_data.csv after dropping invalid rows: (2872352, 4)\n",
      "Resumen del archivo después de la limpieza: user_info_data.csv\n",
      "Número de valores nulos (incluyendo '0' y 0): 17234112\n",
      "Número de 'Sin respuesta': 0\n",
      "Número de 'Sin fecha': 0\n",
      "Resumen del archivo antes de la limpieza: users.csv\n",
      "Número de valores nulos (incluyendo '0' y 0): 417217\n",
      "Número de 'Sin respuesta': 0\n",
      "Número de 'Sin fecha': 0\n",
      "Shape of users.csv before dropping invalid rows: (1450340, 4)\n",
      "Shape of users.csv after dropping invalid rows: (1035821, 4)\n",
      "Resumen del archivo después de la limpieza: users.csv\n",
      "Número de valores nulos (incluyendo '0' y 0): 2071642\n",
      "Número de 'Sin respuesta': 0\n",
      "Número de 'Sin fecha': 0\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\n",
    "    # Paths para los diferentes datasets\n",
    "    input_data_path = educatec_directory_path / \"educatec.csv\"\n",
    "    output_data_path = working_directory_path / \"cleaned_data_educatec.csv\"\n",
    "    cleaning(input_data_path, output_data_path)\n",
    "    \n",
    "    input_data_path = moodle_directory_path / \"course_modules_completion.csv\"\n",
    "    output_data_path = working_directory_path / \"cleaned_data_course_modules_completion.csv\"\n",
    "    cleaning(input_data_path, output_data_path)\n",
    "\n",
    "    input_data_path = moodle_directory_path / \"course_modules.csv\"\n",
    "    output_data_path = working_directory_path / \"cleaned_data_course_modules.csv\"\n",
    "    cleaning(input_data_path, output_data_path)\n",
    "\n",
    "    input_data_path = moodle_directory_path / \"user_info_data.csv\"\n",
    "    output_data_path = working_directory_path / \"cleaned_data_user_info_data.csv\"\n",
    "    cleaning(input_data_path, output_data_path)\n",
    "\n",
    "    input_data_path = moodle_directory_path / \"users.csv\"\n",
    "    output_data_path = working_directory_path / \"cleaned_data_users.csv\"\n",
    "    cleaning(input_data_path, output_data_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
